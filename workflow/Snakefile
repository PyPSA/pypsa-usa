from snakemake.utils import min_version

min_version("6.0")

from shutil import copyfile, move, rmtree
from snakemake.remote.HTTP import RemoteProvider as HTTPRemoteProvider

HTTP = HTTPRemoteProvider()

# -------------------------- Imports and Parameters -------------------------- #

from os.path import normpath
from pathlib import Path

FIGURES_SINGLE = [
    "capacity_map_base",
    "capacity_map_optimized",
    "capacity_map_optimized_brownfield",
    "capacity_map_new",
    "demand_map",
    "costs_bar",
    "production_bar",
    "production_area",
    "emissions_area",
    "emissions_accumulated_tech",
    "emissions_map",
    "renewable_potential_map",
    "capacity_additions_bar",
]

FIGURES_VALIDATE = [
    "seasonal_stacked_plot",
    "carrier_production_bar",
    "production_deviation_bar",
]

FIGURES_SINGLE_HTML = [
    "production_area_html",
    "emissions_area_html",
    "emissions_region_html",
    "emissions_accumulated_tech_html",
]

# --------------------------- Workflow constraints --------------------------- #


localrules:
    dag,
    clean,


wildcard_constraints:
    interconnect="usa|texas|western|eastern",
    simpl="[a-zA-Z0-9]*|all",
    clusters="[0-9]+m?|all",
    ll="(v|c)([0-9\.]+|opt|all)|all",
    opts="[-+a-zA-Z0-9\.]*",
    scope="urban|rural|total",
    sector="([EG]-)*[EG]",


# -------------------------- Config and Subworkflows ------------------------- #


# Merge subworkflow configs and main config
# configfile: "config/tests/config.test_simple.yaml"
configfile: "config/config.default_r.yaml"
configfile: "config/config.cluster.yaml"
configfile: "config/config.osw.yaml"
configfile: "config/config.plotting.yaml"


ATLITE_NPROCESSES = config["atlite"].get("nprocesses", 4)

run = config.get("run", {})
RDIR = run["name"] + "/" if run.get("name") else ""
CDIR = RDIR if not run.get("shared_cutouts") else ""

LOGS = "logs/" + RDIR
BENCHMARKS = "benchmarks/" + RDIR
DATA = "data/"
RESOURCES = "resources/" + RDIR if not run.get("shared_resources") else "resources/"
RESULTS = "results/" + RDIR


include: "rules/common.smk"
include: "rules/retrieve.smk"
include: "rules/build_electricity.smk"
include: "rules/build_sector.smk"
include: "rules/solve_electricity.smk"
include: "rules/postprocess.smk"
include: "rules/validate.smk"


if "E" not in config["scenario"]["sector"]:
    if not config["scenario"]["sector"]:
        config["scenario"]["sector"] = "E"
    else:
        config["scenario"]["sector"] = f"E-{config['scenario']['sector']}"

if config["run"]["validation"]:
    COLLECT_FIGURES = FIGURES_VALIDATE
else:
    COLLECT_FIGURES = FIGURES_SINGLE

# ----------------------------------- Rules ---------------------------------- #


rule all:
    input:
        expand(
            RESULTS
            + "{interconnect}/figures/cluster_{clusters}/l{ll}_{opts}_{sector}_{figure}.pdf",
            **config["scenario"],
            figure=FIGURES_SINGLE
        ),
        #"repo_data/dag.jpg",


# Create DAG with-
# snakemake --dag -F | sed -n "/digraph/,\$p" | dot -Tpng -o repo_data/dag.jpg
# snakemake --rulegraph all | sed -n "/digraph/,\$p" | dot -Tpng -o repo_data/dag.jpg
rule dag:
    message:
        "Creating DAG of workflow."
    output:
        dot="repo_data/dag.dot",
        jpg="repo_data/dag.jpg",
    conda:
        "envs/environment.yaml"
    shell:
        """
        snakemake --rulegraph all | sed -n "/digraph/,\$p" > {output.dot}
        dot -Tjpg -o {output.jpg} {output.dot}
        """


rule clean:
    message:
        "Remove all build results but keep downloaded data."
    run:
        import shutil

        shutil.rmtree("resources", ignore_errors=True)
        shutil.rmtree("results", ignore_errors=True)
        print("Data downloaded to data/ has not been cleaned.")
