from snakemake.utils import min_version
min_version("6.0")

from shutil import copyfile, move, rmtree
from snakemake.remote.HTTP import RemoteProvider as HTTPRemoteProvider

HTTP = HTTPRemoteProvider()

# -------------------------- Imports and Parameters -------------------------- #

from os.path import normpath
from pathlib import Path

FIGURES_SINGLE = [
    "capacity_map_base",
    "capacity_map_optimized",
    "capacity_map_optimized_brownfield",
    "capacity_map_new",
    "costs_bar",
    "production_bar",
    "production_area",
    "emissions_area",
    "emissions_accumulated",
    "emissions_accumulated_tech",
    "emissions_map",
    "renewable_potential_map",
    "capacity_additions_bar"
]

FIGURES_VALIDATE = [
    "seasonal_stacked_plot",
    "carrier_production_bar",
    "production_deviation_bar"
]

FIGURES_SINGLE_HTML = [
    "production_area_html",
    "emissions_area_html",
    # "emissions_node_html",
    "emissions_region_html",
    "emissions_accumulated_tech_html"
]

# --------------------------- Workflow constraints --------------------------- #

localrules:
    dag,
    clean,

wildcard_constraints:
    interconnect="usa|texas|western|eastern",
    simpl="[a-zA-Z0-9]*|all",
    clusters="[0-9]+m?|all",
    ll="(v|c)([0-9\.]+|opt|all)|all",
    opts="[-+a-zA-Z0-9\.]*",


# -------------------------- Config and Subworkflows ------------------------- #

# Merge subworkflow configs and main config
configfile: "config/config.default.yaml"
configfile: "config/config.cluster.yaml"
configfile: "config/config.osw.yaml"
configfile: "config/config.plotting.yaml"

ATLITE_NPROCESSES = config["atlite"].get("nprocesses", 4)

run = config.get("run", {})
RDIR = run["name"] + "/" if run.get("name") else ""
CDIR = RDIR if not run.get("shared_cutouts") else ""

LOGS = "logs/" + RDIR
BENCHMARKS = "benchmarks/" + RDIR
DATA = "data/" + RDIR
RESOURCES = "resources/" + RDIR if not run.get("shared_resources") else "resources/"
RESULTS = "results/" + RDIR

include: "rules/common.smk"
include: "rules/retrieve.smk"
include: "rules/build_electricity.smk"
include: "rules/build_sector.smk"
include: "rules/solve_electricity.smk"
include: "rules/postprocess.smk"

# ----------------------------------- Rules ---------------------------------- #

rule all:
    input:
        expand(
            "results/{interconnect}/figures/cluster_{clusters}/l{ll}_{opts}_{figure}.pdf",
            **config["scenario"],
            figure=FIGURES_SINGLE + FIGURES_VALIDATE,
        ),
        "repo_data/dag.jpg",

# Create DAG with- 
# snakemake --dag -F | sed -n "/digraph/,\$p" | dot -Tpng -o repo_data/dag.jpg
# snakemake --rulegraph all | sed -n "/digraph/,\$p" | dot -Tpng -o repo_data/dag.jpg
rule dag:
    message:
        "Creating DAG of workflow."
    output:
        dot="repo_data/dag.dot",
        jpg="repo_data/dag.jpg",
    shell:
        """
        snakemake --rulegraph all | sed -n "/digraph/,\$p" > {output.dot}
        dot -Tjpg -o {output.jpg} {output.dot}
        """

rule clean:
    message:
        "Remove all build results but keep downloaded data."
    run:
        import shutil
        shutil.rmtree("resources", ignore_errors=True)
        shutil.rmtree("results", ignore_errors=True)
        print("Data downloaded to data/ has not been cleaned.")
